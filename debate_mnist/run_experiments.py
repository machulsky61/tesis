import subprocess
import sys
import os
import json
from datetime import datetime
from collections import defaultdict
from utils.paths import get_config_path

class ExperimentManager:
    def __init__(self):
        self.experiments = []
        self.available_judges = []
        # Global configuration - set once and reused
        self.global_config = {
            'judge_name': "28",  # default judge
            'resolution': 28,  # default resolution
            'k': 6,  # default pixels
            'thr': 0.0,
            'default_images_greedy': 1000,
            'default_images_mcts': 100,  # updated value
            'default_rollouts': 512,  # updated value
            'seed': 42,
            'allow_all_pixels': False,
            'track_confidence': False
        }
        # Experiment-specific configuration
        self.config = {
            'viz_enabled': False,
            'viz_colored': False,
            'viz_metadata': False,
            'save_images': False,
            'save_masks': False,
            'save_play': False,
            'save_confidence': False,
            'save_json': False,  # New comprehensive JSON format
            'track_logits': False,
            'track_logits_progressive': False,
            'save_raw_logits': False
        }
        
    def print_banner(self):
        print("=" * 80)
        print()
        print("üß™ AI SAFETY DEBATE - EXPERIMENT AUTOMATION v3.5 üß™")


    def get_input(self, prompt, default=None, options=None, input_type=str):
        """Gets user input with validation."""
        while True:
            if default is not None:
                user_input = input(f"{prompt} [{default}]: ").strip()
                if not user_input:
                    return default
            else:
                user_input = input(f"{prompt}: ").strip()
            
            if options and user_input.lower() not in [opt.lower() for opt in options]:
                print(f"‚ùå Invalid option. Options: {', '.join(options)}")
                continue
            
            try:
                if input_type == int:
                    return int(user_input)
                elif input_type == float:
                    return float(user_input)
                return user_input
            except ValueError:
                print(f"‚ùå Please enter a valid {input_type.__name__}")

    def get_yes_no(self, prompt, default="n"):
        """Gets yes/no response from user."""
        response = self.get_input(f"{prompt} (y/n)", default, ["y", "n", "yes", "no"])
        return response.lower() in ["y", "yes"]

    def check_judge_exists(self, judge_name):
        """Checks if a judge model exists."""
        return os.path.exists(f"models/{judge_name}.pth")

    def detect_judge_params(self, judge_name):
        """Detecta par√°metros del juez bas√°ndose en el nombre."""
        # Resoluci√≥n
        if "16" in judge_name:
            resolution = 16
        else:
            resolution = 28
        
        # P√≠xeles (k)
        if "_4px" in judge_name:
            k = 4
        elif "_3px" in judge_name:
            k = 3
        elif "_5px" in judge_name:
            k = 5
        elif "_8px" in judge_name:
            k = 8
        elif "_10px" in judge_name:
            k = 10
        else:
            k = 6  # default
            
        return resolution, k

    def scan_available_judges(self):
        """Escanea todos los jueces disponibles en models/"""
        self.available_judges = []
        if os.path.exists("models"):
            for file in os.listdir("models"):
                if file.endswith(".pth"):
                    judge_name = file[:-4]  # remover .pth
                    self.available_judges.append(judge_name)
        
        # Ordenar: primero los est√°ndar, luego los custom
        standard = ["28", "16", "28_4px", "16_4px"]
        self.available_judges.sort(key=lambda x: (x not in standard, x))

    def ask_override_global(self, param_name, current_value, description):
        """Pregunta si el usuario quiere cambiar un par√°metro global."""
        if current_value is not None:
            return self.get_yes_no(f"¬øCambiar {description} (actual: {current_value})?")
        return True

    def show_main_menu(self):
        """Muestra el men√∫ principal."""
        while True:
            print("\n" + "="*80)
            print("üìã MEN√ö PRINCIPAL")
            print("="*80)
            print("1. üéì Entrenar nuevos modelos juez")
            print("2. üî¨ Configurar y ejecutar experimentos")
            print("3. üéØ Evaluar capacidades del juez")
            print("4. üìä An√°lisis de tesis y visualizaciones")
            print("5. üìà Ver resultados anteriores")
            print("6. üíæ Cargar configuraci√≥n guardada")
            print("7. üìù Crear template de experimentos")
            print("8. ‚ùå Salir")
            
            choice = self.get_input("Selecciona una opci√≥n", "2", ["1", "2", "3", "4", "5", "6", "7", "8"])
            
            if choice == "1":
                self.train_judges()
            elif choice == "2":
                self.configure_experiments()
            elif choice == "3":
                self.evaluate_judge()
            elif choice == "4":
                self.thesis_analysis()
            elif choice == "5":
                self.show_previous_results()
            elif choice == "6":
                self.load_configuration()
            elif choice == "7":
                self.create_template()
            elif choice == "8":
                print("üëã ¬°Hasta luego!")
                sys.exit(0)

    def thesis_analysis(self):
        """Sistema completo de an√°lisis de tesis."""
        print("\n" + "="*80)
        print("üìä AN√ÅLISIS DE TESIS Y VISUALIZACIONES")
        print("="*80)
        print("Complete system for generating debate experiment data.")
        print("\nCaracter√≠sticas:")
        print("‚Ä¢ CSV data export for statistical analysis")
        print("‚Ä¢ An√°lisis estad√≠stico con intervalos de confianza")
        print("‚Ä¢ Tablas LaTeX para la tesis")
        print("‚Ä¢ Notebook interactivo Jupyter")
        print("‚Ä¢ Validaci√≥n de consistencia de datos")
        
        # Check for available data files
        required_files = ["outputs/debates.csv", "outputs/evaluations.csv"]
        missing_files = [f for f in required_files if not os.path.exists(f)]
        if missing_files:
            print("‚ö†Ô∏è Archivos de datos faltantes:")
            for f in missing_files:
                print(f"  ‚Ä¢ {f}")
            print("\nEjecuta experimentos primero para generar datos.")
            if not self.get_yes_no("¬øContinuar de todas formas?"):
                return
        
        while True:
            print("\n" + "="*60)
            print("üìã OPCIONES DE AN√ÅLISIS")
            print("="*60)
            print("1. üìà Generate analysis data (CSV export)")
            print("2. üîç An√°lisis de datos interactivo")
            print("3. üìä Resumen estad√≠stico completo")
            print("4. üìã Validaci√≥n de consistencia de datos")
            print("5. üìà Custom data analysis")
            print("6. üìù Generar tablas LaTeX")
            print("7. üìì Abrir Jupyter notebook interactivo")
            print("8. üöÄ Complete data analysis workflow")
            print("0. ‚Ü©Ô∏è Volver al men√∫ principal")
            
            choice = self.get_input("Selecciona opci√≥n", "1", ["0", "1", "2", "3", "4", "5", "6", "7", "8"])
            
            if choice == "0":
                break
            elif choice == "1":
                self._generate_all_thesis_figures()
            elif choice == "8":
                self._complete_thesis_analysis()

    def _generate_all_thesis_figures(self):
        """Analysis and visualization features have been moved to private development module."""
        print("\nüìä Analysis and Visualization Module")
        print("=" * 50)
        print("The analysis and visualization capabilities have been moved to a private")
        print("development module for specialized thesis work.")
        print()
        print("Available analysis tools:")
        print("‚Ä¢ scripts/analyze_results.py - Basic statistical analysis")
        print("‚Ä¢ Manual data analysis using CSV outputs")
        print("‚Ä¢ Custom visualization development as needed")
        print()
        print("üí° Tip: Use the CSV outputs (debates.csv, evaluations.csv) for custom analysis")

    def _complete_thesis_analysis(self):
        """An√°lisis completo de tesis."""
        print("\nüöÄ AN√ÅLISIS COMPLETO DE TESIS")
        print("=" * 50)
        print("Executing complete data analysis workflow")
        
        self._generate_all_thesis_figures()
        print("\nüéâ AN√ÅLISIS COMPLETO FINALIZADO")
        print("üìã Archivos generados:")
        print("‚Ä¢ analysis/output/ - Figuras PNG de alta calidad")
        print("‚Ä¢ outputs/ - CSVs con datos de experimentos")
        print("‚Ä¢ Salida de consola - Estad√≠sticas y tablas LaTeX")

    def train_judges(self):
        """Maneja el entrenamiento de modelos juez."""
        print("\n" + "="*80)
        print("üéì ENTRENAMIENTO DE MODELOS JUEZ")
        print("="*80)
        print("Entrena modelos SparseCNN para diferentes configuraciones de resoluci√≥n y k.")
        
        # Configuraciones est√°ndar expandidas
        standard_configs = [
            ("28", 28, 6, "Resoluci√≥n 28x28, 6 p√≠xeles (PRINCIPAL)"),
            ("16", 16, 6, "Resoluci√≥n 16x16, 6 p√≠xeles"),
            ("28_4px", 28, 4, "Resoluci√≥n 28x28, 4 p√≠xeles"),
            ("16_4px", 16, 4, "Resoluci√≥n 16x16, 4 p√≠xeles"),
            ("28_3px", 28, 3, "Resoluci√≥n 28x28, 3 p√≠xeles"),
            ("28_5px", 28, 5, "Resoluci√≥n 28x28, 5 p√≠xeles"),
            ("28_8px", 28, 8, "Resoluci√≥n 28x28, 8 p√≠xeles"),
        ]
        
        print("\nüìä Estado de modelos juez:")
        print("-" * 60)
        for i, (judge_name, resolution, k, description) in enumerate(standard_configs, 1):
            status = "‚úÖ" if self.check_judge_exists(judge_name) else "‚ùå"
            print(f"{i:2d}. {status} {judge_name:<12} - {description}")
        
        print(f"\n{len(standard_configs)+1}. üîß Configuraci√≥n personalizada")
        print(f"{len(standard_configs)+2}. ‚Ü©Ô∏è  Volver al men√∫ principal")
        
        # Selecci√≥n m√∫ltiple
        judges_to_train = []
        while True:
            choice = self.get_input("\nSelecciona opci√≥n (o 'done' para terminar)", 
                                  str(len(standard_configs)+2))
            
            if choice.lower() == 'done' or choice == str(len(standard_configs)+2):
                break
                
            if choice == str(len(standard_configs)+1):
                # Configuraci√≥n personalizada
                custom_name = self.get_input("Nombre del juez personalizado")
                custom_resolution = self.get_input("Resoluci√≥n", "28", input_type=int)
                custom_k = self.get_input("N√∫mero de p√≠xeles (k)", "6", input_type=int)
                custom_epochs = self.get_input("√âpocas", "64", input_type=int)
                judges_to_train.append((custom_name, custom_resolution, custom_k, 
                                      custom_epochs, "Personalizado"))
            else:
                try:
                    idx = int(choice) - 1
                    if 0 <= idx < len(standard_configs):
                        judge_name, resolution, k, description = standard_configs[idx]
                        epochs = self.get_input(f"√âpocas para {judge_name}", "64", input_type=int)
                        judges_to_train.append((judge_name, resolution, k, epochs, description))
                except:
                    print("‚ùå Opci√≥n inv√°lida")
        
        if judges_to_train:
            self._execute_training(judges_to_train)

    def _execute_training(self, judges_to_train):
        """Ejecuta el entrenamiento de los jueces seleccionados."""
        print(f"\nüìã Se entrenar√°n {len(judges_to_train)} modelos:")
        for judge_name, _, _, epochs, desc in judges_to_train:
            print(f"  ‚Ä¢ {judge_name}: {desc} ({epochs} √©pocas)")
        
        if self.get_yes_no("\n¬øProceder con el entrenamiento?"):
            for judge_name, resolution, k, epochs, description in judges_to_train:
                cmd = f"python train_judge.py --judge_name {judge_name} --resolution {resolution} --k {k} --epochs {epochs}"
                if self.run_command(cmd, f"Entrenando {judge_name}"):
                    print(f"‚úÖ {judge_name} entrenado exitosamente")
                    self.available_judges.append(judge_name)
                else:
                    print(f"‚ùå Error entrenando {judge_name}")
                    if not self.get_yes_no("¬øContinuar con los dem√°s?"):
                        break

    def evaluate_judge(self):
        """Eval√∫a capacidades del juez con diferentes estrategias."""
        print("\n" + "="*80)
        print("üéØ EVALUACI√ìN DE CAPACIDADES DEL JUEZ")
        print("="*80)
        print("Eval√∫a la precisi√≥n del juez con 8 estrategias diferentes de selecci√≥n de p√≠xeles:")
        print("‚Ä¢ Estrategias est√°ticas: random, optimal, adversarial")
        print("‚Ä¢ Agentes secuenciales: greedy, MCTS, adversariales")
        print("‚Ä¢ An√°lisis comparativo y de escalabilidad")
        
        # Escanear jueces disponibles
        self.scan_available_judges()
        
        if not self.available_judges:
            print("‚ùå No hay modelos juez disponibles. Entrena uno primero.")
            return
        
        # Seleccionar juez
        print("\nüìä Modelos juez disponibles:")
        for i, judge in enumerate(self.available_judges, 1):
            res, k = self.detect_judge_params(judge)
            print(f"{i:2d}. {judge} (res: {res}x{res}, k: {k})")
        
        idx = self.get_input("Selecciona juez (n√∫mero)", "1", input_type=int) - 1
        judge_name = self.available_judges[idx]
        resolution, default_k = self.detect_judge_params(judge_name)
        
        while True:
            print("\n" + "="*60)
            print("üìã ESTRATEGIAS DE EVALUACI√ìN")
            print("="*60)
            print("1. üé≤ Random Pixels - Selecci√≥n aleatoria (baseline)")
            print("2. ‚≠ê Optimal Pixels - P√≠xeles que maximizan confianza")
            print("3. üíÄ Adversarial Pixels - P√≠xeles que minimizan confianza")
            print("4. üö´ Adversarial Non-Zero - Adversariales SIN p√≠xeles negros")
            print("5. ü§ñ Greedy Agent - Selecci√≥n secuencial con agente Greedy")
            print("6. üß† MCTS Agent - Selecci√≥n secuencial con agente MCTS")
            print("7. üíÄ Greedy Adversarial Agent - Minimiza logits de clase verdadera")
            print("8. üß† MCTS Adversarial Agent - MCTS que maximiza predicciones incorrectas")
            print("9. üìä Comparison Suite - Comparar todas las estrategias")
            print("10. üî¨ K-Range Analysis - Analizar diferentes valores de k")
            print("0. ‚Ü©Ô∏è  Volver al men√∫ principal")
            
            choice = self.get_input("Selecciona estrategia", "9", 
                                  ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10"])
            
            if choice == "0":
                break
            elif choice == "1":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "random")
            elif choice == "2":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "optimal")
            elif choice == "3":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "adversarial")
            elif choice == "4":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "adversarial_nonzero")
            elif choice == "5":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "greedy_agent")
            elif choice == "6":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "mcts_agent")
            elif choice == "7":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "greedy_adversarial_agent")
            elif choice == "8":
                self._evaluate_single_strategy(judge_name, resolution, default_k, "mcts_adversarial_agent")
            elif choice == "9":
                self._evaluate_comparison_suite(judge_name, resolution, default_k)
            elif choice == "10":
                self._evaluate_k_range_analysis(judge_name, resolution, default_k)

    def _evaluate_comparison_suite(self, judge_name, resolution, default_k):
        """Ejecuta comparaci√≥n completa de estrategias."""
        print("\nüìä SUITE DE COMPARACI√ìN COMPLETA")
        print("-" * 50)
        print("Compara todas las estrategias de evaluaci√≥n del juez:")
        print("‚Ä¢ Est√°ticas: random, optimal, adversarial, adversarial_nonzero")
        print("‚Ä¢ Agentes: greedy, MCTS, greedy adversarial, MCTS adversarial")
        
        k = self.get_input("N√∫mero de p√≠xeles (k)", str(default_k), input_type=int)
        n_images = self.get_input("Im√°genes por estrategia", "500", input_type=int)
        thr = self.get_input("Threshold", "0.0", input_type=float)
        
        include_agents = self.get_yes_no("¬øIncluir estrategias de agentes (m√°s lento)?", "y")
        allow_all_pixels = self.get_yes_no("¬øPermitir p√≠xeles negros para agentes?")
        save_comparison_outputs = self.get_yes_no("¬øGuardar visualizaciones para comparaci√≥n (una muestra por estrategia)?")
        
        strategies = ["random", "optimal", "adversarial", "adversarial_nonzero"]
        
        if include_agents:
            strategies.extend(["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"])
            rollouts = self.get_input("Rollouts para MCTS agents", "300", input_type=int)
        
        print(f"\nüöÄ Ejecutando comparaci√≥n con k={k}, {n_images} im√°genes cada una...")
        print(f"Estrategias: {', '.join(strategies)}")
        
        for strategy in strategies:
            cmd = (f"python eval_judge.py --judge_name {judge_name} --resolution {resolution} "
                   f"--strategy {strategy} --k {k} --n_images {n_images} --thr {thr}")
            
            if strategy in ["mcts_agent", "mcts_adversarial_agent"]:
                cmd += f" --rollouts {rollouts}"
                
            if strategy in ["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"] and allow_all_pixels:
                cmd += " --allow_all_pixels"
            
            # Add saving options for comparison visualizations
            if save_comparison_outputs:
                # Save only a few samples for comparison purposes
                cmd += " --save_visualizations"
                # Limit to fewer images when saving outputs to avoid clutter
                if n_images > 50:
                    cmd = cmd.replace(f"--n_images {n_images}", "--n_images 10")
                    print(f"‚ÑπÔ∏è  Limitando a 10 im√°genes para {strategy} (visualizaci√≥n habilitada)")
            
            if self.run_command(cmd, f"Comparaci√≥n - {strategy.replace('_', ' ').title()}"):
                print(f"‚úÖ {strategy.replace('_', ' ').title()} completado")
            else:
                print(f"‚ùå Error en {strategy}")
                if not self.get_yes_no("¬øContinuar con las dem√°s estrategias?"):
                    break
        
        print("\nüìä Suite de comparaci√≥n completada.")
        print("üìÅ Resultados guardados en outputs/evaluations.csv")
        if save_comparison_outputs:
            print("üìÅ Visualizaciones guardadas en outputs/visualizations/evaluations/")
        print("üí° Use option 4 (Data Analysis) to export CSV data for analysis")

    def _evaluate_single_strategy(self, judge_name, resolution, default_k, strategy):
        """Ejecuta evaluaci√≥n de una estrategia espec√≠fica."""
        print(f"\nüéØ EVALUACI√ìN - {strategy.replace('_', ' ').title()}")
        print("-" * 50)
        
        k = self.get_input("N√∫mero de p√≠xeles (k)", str(default_k), input_type=int)
        n_images = self.get_input("N√∫mero de im√°genes", "500", input_type=int)
        thr = self.get_input("Threshold", "0.0", input_type=float)
        
        cmd = (f"python eval_judge.py --judge_name {judge_name} --resolution {resolution} "
               f"--strategy {strategy} --k {k} --n_images {n_images} --thr {thr} "
               f"--seed {self.global_config['seed']}")
        
        # Opciones espec√≠ficas para agentes
        if strategy in ["mcts_agent", "mcts_adversarial_agent"]:
            rollouts = self.get_input("Rollouts para MCTS", "300", input_type=int)
            cmd += f" --rollouts {rollouts}"
        
        if strategy in ["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"]:
            if self.get_yes_no("¬øPermitir selecci√≥n de p√≠xeles negros?"):
                cmd += " --allow_all_pixels"
        
        # Ask about saving evaluation outputs
        print("\nüìÅ Opciones de guardado para evaluaci√≥n:")
        save_outputs = self.get_yes_no("¬øGuardar im√°genes y visualizaciones de la evaluaci√≥n?")
        if save_outputs:
            cmd += " --save_metadata"  # This includes images, masks, and visualizations
        
        cmd += f' --note "single_eval_{strategy}"'
        
        if self.run_command(cmd, f"Evaluaci√≥n {strategy.replace('_', ' ').title()}"):
            print(f"‚úÖ Evaluaci√≥n {strategy} completada")
            if save_outputs:
                print(f"üìÅ Archivos guardados en outputs/visualizations/evaluations/")
            print("üìÅ Resultados guardados en outputs/evaluations.csv")
        else:
            print(f"‚ùå Error en evaluaci√≥n {strategy}")

    def _evaluate_k_range_analysis(self, judge_name, resolution, default_k):
        """Analiza diferentes valores de k para una estrategia."""
        print("\nüî¨ AN√ÅLISIS DE RANGO K")
        print("-" * 50)
        print("Eval√∫a c√≥mo cambia la precisi√≥n del juez con diferentes valores de k")
        
        strategy = self.get_input("Estrategia a analizar", "random", 
                                ["random", "optimal", "adversarial", "adversarial_nonzero", 
                                 "greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"])
        
        print("Selecciona valores de k a probar:")
        k_values = []
        for k in [1, 2, 3, 4, 5, 6, 7, 8, 10, 12]:
            if self.get_yes_no(f"  ‚Ä¢ k = {k}"):
                k_values.append(k)
        
        if not k_values:
            return
            
        n_images = self.get_input("Im√°genes por valor de k", "300", input_type=int)
        thr = self.get_input("Threshold", "0.0", input_type=float)
        
        if strategy in ["mcts_agent", "mcts_adversarial_agent"]:
            rollouts = self.get_input("Rollouts para MCTS", "200", input_type=int)
        
        allow_all_pixels = False
        if strategy in ["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"]:
            allow_all_pixels = self.get_yes_no("¬øPermitir p√≠xeles negros?")
        
        save_k_analysis_outputs = self.get_yes_no("¬øGuardar visualizaciones para an√°lisis k (pocas muestras)?")
        
        print(f"\nüöÄ Ejecutando an√°lisis de k para {strategy}...")
        print(f"Valores de k: {k_values}")
        
        for k in k_values:
            cmd = (f"python eval_judge.py --judge_name {judge_name} --resolution {resolution} "
                   f"--strategy {strategy} --k {k} --n_images {n_images} --thr {thr} "
                   f"--seed {self.global_config['seed']}")
            
            if strategy in ["mcts_agent", "mcts_adversarial_agent"]:
                cmd += f" --rollouts {rollouts}"
            
            if allow_all_pixels:
                cmd += " --allow_all_pixels"
            
            # Add saving options for k analysis
            if save_k_analysis_outputs:
                cmd += " --save_visualizations"
                # Limit to very few images for k analysis
                if n_images > 20:
                    cmd = cmd.replace(f"--n_images {n_images}", "--n_images 5")
                    print(f"‚ÑπÔ∏è  Limitando a 5 im√°genes para k={k} (visualizaci√≥n habilitada)")
            
            cmd += f' --note "k_analysis_{strategy}_k{k}"'
            
            if self.run_command(cmd, f"K-Analysis {strategy} k={k}"):
                print(f"‚úÖ k={k} completado")
            else:
                print(f"‚ùå Error con k={k}")
                if not self.get_yes_no("¬øContinuar con los dem√°s valores?"):
                    break
        
        print("\nüìä An√°lisis de rango K completado")
        print("üìÅ Resultados guardados en outputs/evaluations.csv")

    def configure_experiments(self):
        """Configuraci√≥n principal de experimentos."""
        print("\n" + "="*80)
        print("üî¨ CONFIGURACI√ìN DE EXPERIMENTOS")
        print("="*80)
        print("Sistema inteligente de configuraci√≥n con:")
        print("‚Ä¢ Configuraci√≥n global reutilizable")
        print("‚Ä¢ 9 tipos de experimentos automatizados")
        print("‚Ä¢ Opciones granulares de guardado")
        print("‚Ä¢ Gesti√≥n de cola de experimentos")
        
        # Escanear jueces disponibles
        self.scan_available_judges()
        
        if not self.available_judges:
            print("‚ùå No hay modelos juez disponibles. Entrena uno primero.")
            return
        
        # Configurar par√°metros globales
        self._configure_global_parameters()
        
        # Configurar visualizaciones
        self._configure_visualizations()
        
        # Configurar tracking de logits
        self._configure_logits_tracking()
        
        # Men√∫ de experimentos
        self._experiment_selection_menu()

    def _configure_global_parameters(self):
        """Configura par√°metros globales que se reutilizan."""
        print("\n‚öôÔ∏è CONFIGURACI√ìN GLOBAL")
        print("-" * 60)
        print("Estos par√°metros se aplicar√°n a todos los experimentos")
        
        # Selecci√≥n de juez
        if self.global_config['judge_name'] is None or self.ask_override_global('judge_name', self.global_config['judge_name'], 'juez'):
            print("\nüìä Modelos juez disponibles:")
            for i, judge in enumerate(self.available_judges, 1):
                res, k = self.detect_judge_params(judge)
                print(f"{i:2d}. {judge} (res: {res}x{res}, k: {k})")
            
            idx = self.get_input("Selecciona juez (n√∫mero)", "1", input_type=int) - 1
            self.global_config['judge_name'] = self.available_judges[idx]
            detected_resolution, detected_k = self.detect_judge_params(self.global_config['judge_name'])
            self.global_config['resolution'] = detected_resolution
            
            # Preguntar sobre k
            if self.get_yes_no(f"¬øUsar k={detected_k} detectado del juez?", "y"):
                self.global_config['k'] = detected_k
            else:
                self.global_config['k'] = self.get_input("N√∫mero de p√≠xeles (k) global", "6", input_type=int)
        
        # Otros par√°metros globales
        if self.ask_override_global('defaults', None, 'valores por defecto'):
            self.global_config['default_images_greedy'] = self.get_input(
                "Im√°genes por defecto para Greedy", str(self.global_config['default_images_greedy']), input_type=int)
            self.global_config['default_images_mcts'] = self.get_input(
                "Im√°genes por defecto para MCTS", str(self.global_config['default_images_mcts']), input_type=int)
            self.global_config['default_rollouts'] = self.get_input(
                "Rollouts por defecto para MCTS", str(self.global_config['default_rollouts']), input_type=int)
        
        if self.ask_override_global('advanced', None, 'opciones avanzadas'):
            self.global_config['allow_all_pixels'] = self.get_yes_no(
                "¬øPermitir selecci√≥n irrestricta de p√≠xeles?")
            self.global_config['track_confidence'] = self.get_yes_no(
                "¬øTrackear probabilidades del juez (para an√°lisis estad√≠stico)?")
        
        print("\n‚úÖ Configuraci√≥n global establecida:")
        print(f"  ‚Ä¢ Juez: {self.global_config['judge_name']} (res: {self.global_config['resolution']}, k: {self.global_config['k']})")
        print(f"  ‚Ä¢ Im√°genes defecto: Greedy={self.global_config['default_images_greedy']}, MCTS={self.global_config['default_images_mcts']}")
        print(f"  ‚Ä¢ Rollouts defecto: {self.global_config['default_rollouts']}")

    def _configure_visualizations(self):
        """Configura opciones granulares de guardado."""
        print("\nüé® CONFIGURACI√ìN DE GUARDADO")
        print("-" * 50)
        print("Controla qu√© se guarda durante los experimentos")
        
        self.config['viz_enabled'] = self.get_yes_no("¬øHabilitar visualizaciones/guardado?")
        if self.config['viz_enabled']:
            print("\nüì¶ M√©todo de configuraci√≥n:")
            print("1. Presets r√°pidos (recomendado)")
            print("2. Selecci√≥n individual (control total)")
            method = self.get_input("Elige m√©todo", "1", options=["1", "2"])
            
            if method == "1":
                preset = self.get_input(
                    "Elige preset", "minimal", 
                    options=["minimal", "standard", "complete", "analysis", "json"])
                
                if preset == "minimal":
                    self.config.update({
                        'save_images': False, 'save_masks': False, 
                        'save_play': False, 'viz_colored': False, 
                        'save_confidence': False, 'save_json': False
                    })
                    print("‚úÖ Minimal: Solo resultados CSV (m√°xima velocidad)")
                elif preset == "standard":
                    self.config.update({
                        'save_images': False, 'save_masks': False, 
                        'save_play': True, 'viz_colored': True, 
                        'save_confidence': False, 'save_json': False
                    })
                    print("‚úÖ Standard: Debates coloreados + secuencias")
                elif preset == "complete":
                    self.config.update({
                        'save_images': True, 'save_masks': True, 
                        'save_play': True, 'viz_colored': True, 
                        'save_confidence': True, 'save_json': False
                    })
                    print("‚úÖ Complete: Todas las visualizaciones y metadata")
                elif preset == "analysis":
                    self.config.update({
                        'save_images': False, 'save_masks': False, 
                        'save_play': True, 'viz_colored': False, 
                        'save_confidence': True, 'save_json': False
                    })
                    print("‚úÖ Analysis: Optimizado para an√°lisis estad√≠stico")
                elif preset == "json":
                    self.config.update({
                        'save_images': False, 'save_masks': False, 
                        'save_play': False, 'viz_colored': False, 
                        'save_confidence': False, 'save_json': True
                    })
                    print("‚úÖ JSON: Formato comprehensivo completo (reemplaza save_play)")
            else:
                # Selecci√≥n individual
                print("\nüìÅ Opciones individuales:")
                self.config['save_images'] = self.get_yes_no("  üñºÔ∏è  ¬øGuardar im√°genes originales?")
                self.config['save_masks'] = self.get_yes_no("  üé≠ ¬øGuardar im√°genes enmascaradas?")
                self.config['save_play'] = self.get_yes_no("  üìú ¬øGuardar secuencias de juego?")
                self.config['viz_colored'] = self.get_yes_no("  üé® ¬øGuardar debates coloreados?")
                self.config['save_confidence'] = self.get_yes_no("  üìä ¬øGuardar an√°lisis de probabilidades (track_confidence)?")
                self.config['save_json'] = self.get_yes_no("  üìÑ ¬øGuardar JSON comprehensivo?")
                
                # Mostrar advertencia si se seleccionan opciones redundantes
                if self.config['save_json'] and self.config['save_play']:
                    print("‚ÑπÔ∏è  NOTA: save_json incluye toda la funcionalidad de save_play")
                    if self.get_yes_no("  ¬øDesactivar save_play para evitar redundancia?"):
                        self.config['save_play'] = False
            
            # Metadata legacy para compatibilidad
            any_metadata = any([
                self.config['save_images'], self.config['save_masks'], 
                self.config['save_play'], self.config['save_confidence'],
                self.config['save_json']
            ])
            self.config['viz_metadata'] = any_metadata

    def _configure_logits_tracking(self):
        """Configura opciones de tracking de logits del juez."""
        print("\nüß† CONFIGURACI√ìN DE TRACKING DE LOGITS")
        print("-" * 50)
        print("Trackea la evoluci√≥n de las predicciones del juez durante el debate")
        
        track_enabled = self.get_yes_no("¬øHabilitar tracking de logits?", default="n")
        
        if track_enabled:
            print("\nüìä Opciones de tracking:")
            print("1. Solo estado final (b√°sico)")
            print("2. Progresivo - cada p√≠xel (recomendado)")
            print("3. Completo - progresivo + logits crudos")
            
            option = self.get_input("Elige opci√≥n", "2", options=["1", "2", "3"])
            
            if option == "1":
                self.config['track_logits'] = True
                self.config['track_logits_progressive'] = False
                self.config['save_raw_logits'] = False
                print("‚úÖ Tracking b√°sico: Solo estado final del juez")
            elif option == "2":
                self.config['track_logits'] = False
                self.config['track_logits_progressive'] = True
                self.config['save_raw_logits'] = False
                print("‚úÖ Tracking progresivo: Monitoreo despu√©s de cada p√≠xel")
            elif option == "3":
                self.config['track_logits'] = False
                self.config['track_logits_progressive'] = True
                self.config['save_raw_logits'] = True
                print("‚úÖ Tracking completo: Progresivo + logits crudos para an√°lisis")
                
            # Automatically enable JSON when logits tracking is used
            if not self.config.get('save_json', False):
                auto_json = self.get_yes_no("¬øHabilitar JSON autom√°ticamente para guardar logits?", default=True)
                if auto_json:
                    self.config['save_json'] = True
                    print("üìù JSON habilitado autom√°ticamente")
        else:
            self.config['track_logits'] = False
            self.config['track_logits_progressive'] = False
            self.config['save_raw_logits'] = False
            print("‚ùå Tracking de logits deshabilitado")

    def _get_advanced_flags(self):
        """Genera flags avanzados para comandos de debate."""
        flags = ""
        
        if self.global_config['allow_all_pixels']:
            flags += " --allow_all_pixels"
        
        if self.global_config['track_confidence'] or self.config['save_confidence']:
            flags += " --track_confidence"
        
        # Logits tracking options
        if self.config.get('track_logits'):
            flags += " --track_logits"
        
        if self.config.get('track_logits_progressive'):
            flags += " --track_logits_progressive"
        
        if self.config.get('save_raw_logits'):
            flags += " --save_raw_logits"
        
        # Comprehensive JSON format (replaces save_play, includes confidence_progression)
        if self.config['save_json']:
            flags += " --save_json"
        
        # Opciones granulares de guardado
        if self.config['viz_enabled']:
            if self.config['save_images']:
                flags += " --save_images"
            if self.config['save_masks']:
                flags += " --save_mask"
            if self.config['save_play']:
                flags += " --save_play"
            if self.config['viz_colored']:
                flags += " --save_colored_debate"
            
            # Flag metadata legacy
            if self.config['viz_metadata']:
                flags += " --save_metadata"
        
        return flags

    def _experiment_selection_menu(self):
        """Men√∫ para selecci√≥n de experimentos."""
        while True:
            print("\n" + "="*80)
            print("üìã SELECCI√ìN DE EXPERIMENTOS")
            print("="*80)
            print(f"Juez: {self.global_config['judge_name']} | k: {self.global_config['k']} | "
                  f"Experimentos en cola: {len(self.experiments)}")
            print("-" * 80)
            
            print("1. üîÑ Experimentos Sim√©tricos (mismo tipo de agente)")
            print("2. ‚öîÔ∏è  Experimentos Asim√©tricos (MCTS vs Greedy)")
            print("3. üéØ Experimentos de Ablaci√≥n (variar k)")
            print("4. üìà Curvas de Escalabilidad (rollouts)")
            print("5. üé≤ An√°lisis de Robustez (m√∫ltiples semillas)")
            print("6. üß† Experimentos de Confianza")
            print("7. üö´ Experimentos con P√≠xeles Irrestrictos")
            print("8. ü§ñ Experimentos de Evaluaci√≥n de Juez")
            print("9. üî¨ Experimentos Personalizados")
            print("10. üìä Ver cola de experimentos")
            print("11. üöÄ Ejecutar experimentos")
            print("12. üíæ Guardar configuraci√≥n")
            print("0. ‚Ü©Ô∏è  Volver al men√∫ principal")
            
            choice = self.get_input("Selecciona opci√≥n", "11")
            
            if choice == "1":
                self._add_symmetric_experiments()
            elif choice == "2":
                self._add_asymmetric_experiments()
            elif choice == "3":
                self._add_ablation_experiments()
            elif choice == "4":
                self._add_scalability_experiments()
            elif choice == "5":
                self._add_robustness_experiments()
            elif choice == "6":
                self._add_confidence_experiments()
            elif choice == "7":
                self._add_unrestricted_pixel_experiments()
            elif choice == "8":
                self._add_judge_evaluation_experiments()
            elif choice == "9":
                self._add_custom_experiments()
            elif choice == "10":
                self._show_experiment_queue()
            elif choice == "11":
                self._execute_experiments()
                break
            elif choice == "12":
                self._save_configuration()
            elif choice == "0":
                break

    def _add_symmetric_experiments(self):
        """A√±ade experimentos sim√©tricos a la cola."""
        print("\nüîÑ EXPERIMENTOS SIM√âTRICOS")
        print("-" * 40)
        print("Debates entre agentes del mismo tipo (Greedy vs Greedy, MCTS vs MCTS)")
        
        agent_type = self.get_input("Tipo de agente (greedy/mcts)", "greedy", ["greedy", "mcts"])
        
        variants = []
        if self.get_yes_no("‚Ä¢ Baseline (liar primero, sin precommit)"):
            variants.append(("baseline", "", ""))
        if self.get_yes_no("‚Ä¢ Con precommit"):
            variants.append(("precommit", " --precommit", "precommit"))
        if self.get_yes_no("‚Ä¢ Honest primero"):
            variants.append(("honest_first", " --starts honest", "honest_first"))
        if self.get_yes_no("‚Ä¢ Precommit + Honest primero"):
            variants.append(("precommit_honest", " --precommit --starts honest", "precommit_honest_first"))
        
        if not variants:
            return
        
        # Configuraci√≥n espec√≠fica
        n_images = self.get_input("N√∫mero de im√°genes", 
                                str(self.global_config[f'default_images_{agent_type}']), input_type=int)
        
        rollouts = ""
        if agent_type == "mcts":
            r = self.get_input("Rollouts", str(self.global_config['default_rollouts']), input_type=int)
            rollouts = f" --rollouts {r}"
            
        for variant_name, flags, note in variants:
            advanced_flags = self._get_advanced_flags()
            cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                   f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                   f"--thr {self.global_config['thr']} --agent_type {agent_type} "
                   f"--n_images {n_images} --seed {self.global_config['seed']}{rollouts}{flags}{advanced_flags} "
                   f'--note "{agent_type}_{note}"')
            
            desc = f"{agent_type.upper()} vs {agent_type.upper()} - {variant_name}"
            self.experiments.append((cmd, desc))
            
        print(f"‚úÖ A√±adidos {len(variants)} experimentos sim√©tricos")

    def _add_asymmetric_experiments(self):
        """A√±ade experimentos asim√©tricos a la cola."""
        print("\n‚öîÔ∏è EXPERIMENTOS ASIM√âTRICOS")
        print("-" * 40)
        print("Debates entre agentes de diferente tipo (MCTS vs Greedy)")
        
        honest_agent = self.get_input("Agente honesto (greedy/mcts)", "mcts", ["greedy", "mcts"])
        liar_agent = "greedy" if honest_agent == "mcts" else "mcts"
        
        variants = []
        if self.get_yes_no("‚Ä¢ Baseline"):
            variants.append(("baseline", "", ""))
        if self.get_yes_no("‚Ä¢ Con precommit"):
            variants.append(("precommit", " --precommit", "precommit"))
        
        if not variants:
            return
            
        n_images = self.get_input("N√∫mero de im√°genes", 
                                str(self.global_config['default_images_mcts']), input_type=int)
        rollouts = self.get_input("Rollouts para MCTS", 
                                str(self.global_config['default_rollouts']), input_type=int)
        
        for variant_name, flags, note in variants:
            advanced_flags = self._get_advanced_flags()
            cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                   f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                   f"--thr {self.global_config['thr']} --mixed_agents --honest_agent {honest_agent} "
                   f"--rollouts {rollouts} --n_images {n_images} --seed {self.global_config['seed']}{flags}{advanced_flags} "
                   f'--note "{honest_agent}_honest_vs_{liar_agent}_liar_{note}"')
            
            desc = f"{honest_agent.upper()} Honest vs {liar_agent.upper()} Liar - {variant_name}"
            self.experiments.append((cmd, desc))
            
        print(f"‚úÖ A√±adidos {len(variants)} experimentos asim√©tricos")

    def _add_ablation_experiments(self):
        """A√±ade experimentos de ablaci√≥n variando k."""
        print("\nüéØ EXPERIMENTOS DE ABLACI√ìN (VARIAR K)")
        print("-" * 40)
        print("Estudia el efecto del n√∫mero de p√≠xeles revelados (k) en el rendimiento")
        
        k_values = []
        print("Selecciona valores de k a probar:")
        for k in [3, 4, 5, 6, 7, 8, 10, 12]:
            if self.get_yes_no(f"  ‚Ä¢ k = {k}"):
                k_values.append(k)
        
        if not k_values:
            return
            
        agent_type = self.get_input("Tipo de agente (greedy/mcts)", "greedy", ["greedy", "mcts"])
        n_images = self.get_input("Im√°genes por valor de k", "500", input_type=int)
        
        if agent_type == "mcts":
            rollouts = self.get_input("Rollouts", "200", input_type=int)
            
        # Seleccionar variantes experimentales
        print("\nSelecciona variantes a incluir:")
        variants = []
        if self.get_yes_no("‚Ä¢ Baseline (liar primero, sin precommit)"):
            variants.append(("baseline", "", ""))
        if self.get_yes_no("‚Ä¢ Con precommit"):
            variants.append(("precommit", " --precommit", "precommit"))
        if self.get_yes_no("‚Ä¢ Honest primero"):
            variants.append(("honest_first", " --starts honest", "honest_first"))
        if self.get_yes_no("‚Ä¢ Precommit + Honest primero"):
            variants.append(("precommit_honest", " --precommit --starts honest", "precommit_honest_first"))
            
        # Experimentos asim√©tricos
        asymmetric = self.get_yes_no("‚Ä¢ Incluir experimentos asim√©tricos")
        if asymmetric:
            print("  Configuraci√≥n asim√©trica: un agente greedy vs uno MCTS")
            asymmetric_rollouts = 100
            if agent_type == "mcts":
                asymmetric_rollouts = self.get_input("  Rollouts para MCTS en asim√©trico", "100", input_type=int)
        
        if not variants:
            variants = [("baseline", "", "")]  # Default to baseline if none selected
        
        for k in k_values:
            advanced_flags = self._get_advanced_flags()
            
            # Experimentos sim√©tricos
            for variant_name, variant_flags, variant_suffix in variants:
                cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {k} "
                       f"--thr {self.global_config['thr']} --n_images {n_images} "
                       f"--seed {self.global_config['seed']}")
                
                if agent_type == "mcts":
                    cmd += f" --agent_type mcts --rollouts {rollouts}"
                    desc = f"Ablaci√≥n k={k} - MCTS"
                else:
                    cmd += f" --agent_type greedy"
                    desc = f"Ablaci√≥n k={k} - Greedy"
                
                cmd += variant_flags
                variant_note = f"_{variant_suffix}" if variant_suffix else ""
                cmd += f'{advanced_flags} --note "ablation_k{k}_{agent_type}{variant_note}"'
                
                if variant_suffix:
                    desc += f" - {variant_name}"
                    
                self.experiments.append((cmd, desc))
            
            # Experimentos asim√©tricos
            if asymmetric:
                for variant_name, variant_flags, variant_suffix in variants:
                    # Greedy vs MCTS
                    cmd_asym1 = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                                f"--resolution {self.global_config['resolution']} --k {k} "
                                f"--thr {self.global_config['thr']} --n_images {n_images} "
                                f"--seed {self.global_config['seed']} --mixed_agents "
                                f"--honest_agent greedy --rollouts {asymmetric_rollouts}")
                    cmd_asym1 += variant_flags
                    variant_note = f"_{variant_suffix}" if variant_suffix else ""
                    cmd_asym1 += f'{advanced_flags} --note "ablation_k{k}_asym_greedy_vs_mcts{variant_note}"'
                    desc_asym1 = f"Ablaci√≥n k={k} - Asim√©trico (Greedy vs MCTS)"
                    if variant_suffix:
                        desc_asym1 += f" - {variant_name}"
                    self.experiments.append((cmd_asym1, desc_asym1))
                    
                    # MCTS vs Greedy
                    cmd_asym2 = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                                f"--resolution {self.global_config['resolution']} --k {k} "
                                f"--thr {self.global_config['thr']} --n_images {n_images} "
                                f"--seed {self.global_config['seed']} --mixed_agents "
                                f"--honest_agent mcts --rollouts {asymmetric_rollouts}")
                    cmd_asym2 += variant_flags
                    cmd_asym2 += f'{advanced_flags} --note "ablation_k{k}_asym_mcts_vs_greedy{variant_note}"'
                    desc_asym2 = f"Ablaci√≥n k={k} - Asim√©trico (MCTS vs Greedy)"
                    if variant_suffix:
                        desc_asym2 += f" - {variant_name}"
                    self.experiments.append((cmd_asym2, desc_asym2))
            
        total_experiments = len(k_values) * len(variants) * (3 if asymmetric else 1)
        print(f"‚úÖ A√±adidos {total_experiments} experimentos de ablaci√≥n")

    def _add_scalability_experiments(self):
        """A√±ade experimentos de escalabilidad de rollouts."""
        print("\nüìà CURVAS DE ESCALABILIDAD (ROLLOUTS)")
        print("-" * 40)
        print("Analiza c√≥mo el rendimiento de MCTS escala con el n√∫mero de rollouts")
        
        print("Configurar serie de rollouts:")
        print("1. Serie logar√≠tmica (50, 100, 200, 500, 1000, 2000)")
        print("2. Serie lineal (100, 200, 300, ..., 1000)")
        print("3. Serie personalizada")
        
        choice = self.get_input("Selecciona", "1", ["1", "2", "3"])
        
        if choice == "1":
            rollout_values = [50, 100, 200, 500, 1000, 2000]
        elif choice == "2":
            rollout_values = list(range(100, 1100, 100))
        else:
            rollout_values = []
            print("Ingresa valores de rollouts (escribe 'done' para terminar):")
            while True:
                val = input("Rollouts: ").strip()
                if val.lower() == 'done':
                    break
                try:
                    rollout_values.append(int(val))
                except:
                    print("‚ùå Valor inv√°lido")
        
        # Filtrar seg√∫n recursos computacionales
        if self.get_yes_no("¬øFiltrar valores altos (>2000) por costo computacional?", "y"):
            original_len = len(rollout_values)
            rollout_values = [r for r in rollout_values if r <= 2000]
            if original_len > len(rollout_values):
                print(f"‚ö†Ô∏è  Filtrados {original_len - len(rollout_values)} valores > 2000")
        
        n_images = self.get_input("Im√°genes por punto", str(self.global_config['default_images_mcts']), input_type=int)
        fixed_seed = self.get_yes_no("¬øUsar semilla fija para comparaci√≥n?", "y")
        seed_to_use = self.global_config['seed'] if fixed_seed else None
        
        use_mixed = self.get_yes_no("¬øIncluir agentes mixtos adem√°s de MCTS puro?")
        
        for rollouts in rollout_values:
            # MCTS puro
            advanced_flags = self._get_advanced_flags()
            cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                   f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                   f"--thr {self.global_config['thr']} --agent_type mcts --rollouts {rollouts} "
                   f"--n_images {n_images}")
            
            if seed_to_use:
                cmd += f" --seed {seed_to_use}"
            else:
                cmd += f" --seed {self.global_config['seed']}"
                
            cmd += f'{advanced_flags} --note "scalability_mcts_r{rollouts}"'
            self.experiments.append((cmd, f"Escalabilidad MCTS - {rollouts} rollouts"))
            
            # Mixed si se solicita
            if use_mixed:
                cmd_mixed = cmd.replace("--agent_type mcts", "--mixed_agents --honest_agent mcts")
                cmd_mixed = cmd_mixed.replace("scalability_mcts", "scalability_mixed")
                self.experiments.append((cmd_mixed, f"Escalabilidad Mixed - {rollouts} rollouts"))
                
        print(f"‚úÖ A√±adidos {len(rollout_values) * (2 if use_mixed else 1)} experimentos")

    def _add_robustness_experiments(self):
        """A√±ade experimentos de robustez con m√∫ltiples semillas."""
        print("\nüé≤ AN√ÅLISIS DE ROBUSTEZ (M√öLTIPLES SEMILLAS)")
        print("-" * 40)
        print("Eval√∫a la consistencia de resultados con diferentes semillas aleatorias")
        
        seeds = []
        print("Configurar semillas:")
        print("1. Serie est√°ndar (42, 123, 456, 789, 1337)")
        print("2. Serie personalizada")
        
        choice = self.get_input("Selecciona", "1", ["1", "2"])
        if choice == "1":
            seeds = [42, 123, 456, 789, 1337]
        else:
            n_seeds = self.get_input("N√∫mero de semillas", "5", input_type=int)
            for i in range(n_seeds):
                seed = self.get_input(f"Semilla {i+1}", str(42 + i*100), input_type=int)
                seeds.append(seed)
        
        # Configuraci√≥n base
        agent_type = self.get_input("Tipo de agente (greedy/mcts/mixed)", "greedy", 
                                  ["greedy", "mcts", "mixed"])
        n_images = self.get_input("Im√°genes por semilla", str(self.global_config['default_images_mcts']), input_type=int)
        
        base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                    f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                    f"--thr {self.global_config['thr']} --n_images {n_images}")
        
        if agent_type == "greedy":
            base_cmd += " --agent_type greedy"
        elif agent_type == "mcts":
            rollouts = self.get_input("Rollouts", str(self.global_config['default_rollouts']), input_type=int)
            base_cmd += f" --agent_type mcts --rollouts {rollouts}"
        else:  # mixed
            honest = self.get_input("Agente honesto", "mcts", ["greedy", "mcts"])
            rollouts = self.get_input("Rollouts", str(self.global_config['default_rollouts']), input_type=int)
            base_cmd += f" --mixed_agents --honest_agent {honest} --rollouts {rollouts}"
        
        for seed in seeds:
            advanced_flags = self._get_advanced_flags()
            cmd = base_cmd + f' --seed {seed}{advanced_flags} --note "robustness_{agent_type}_s{seed}"'
            self.experiments.append((cmd, f"Robustez {agent_type} - Semilla {seed}"))
            
        print(f"‚úÖ A√±adidos {len(seeds)} experimentos de robustez")

    def _add_confidence_experiments(self):
        """A√±ade experimentos espec√≠ficos para an√°lisis de confianza."""
        print("\nüß† EXPERIMENTOS DE CONFIANZA")
        print("-" * 40)
        print("Analiza la evoluci√≥n de probabilidades del juez durante los debates")
        print("Estos experimentos fuerzan el tracking de probabilidades para an√°lisis estad√≠stico detallado.")
        
        # Temporalmente forzar track_confidence
        original_track = self.global_config['track_confidence']
        self.global_config['track_confidence'] = True
        
        agent_types = []
        if self.get_yes_no("‚Ä¢ Incluir Greedy vs Greedy"):
            agent_types.append("greedy")
        if self.get_yes_no("‚Ä¢ Incluir MCTS vs MCTS"):
            agent_types.append("mcts")
        if self.get_yes_no("‚Ä¢ Incluir Mixed (MCTS vs Greedy)"):
            agent_types.append("mixed")
        
        if not agent_types:
            self.global_config['track_confidence'] = original_track
            return
        
        n_images = self.get_input("Im√°genes por experimento", str(self.global_config['default_images_mcts']), input_type=int)
        k_values = []
        print("Valores de k para analizar confianza:")
        for k in [3, 4, 5, 6, 8]:
            if self.get_yes_no(f"  ‚Ä¢ k = {k}"):
                k_values.append(k)
        
        if not k_values:
            k_values = [self.global_config['k']]
        
        for agent_type in agent_types:
            for k in k_values:
                advanced_flags = self._get_advanced_flags()
                base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                           f"--resolution {self.global_config['resolution']} --k {k} "
                           f"--thr {self.global_config['thr']} --n_images {n_images} --seed {self.global_config['seed']}{advanced_flags}")
                
                if agent_type == "greedy":
                    cmd = base_cmd + f' --agent_type greedy --note "confidence_greedy_k{k}"'
                    desc = f"Confidence Analysis - Greedy k={k}"
                elif agent_type == "mcts":
                    rollouts = self.get_input(f"Rollouts para MCTS k={k}", str(self.global_config['default_rollouts']), input_type=int)
                    cmd = base_cmd + f' --agent_type mcts --rollouts {rollouts} --note "confidence_mcts_k{k}_r{rollouts}"'
                    desc = f"Confidence Analysis - MCTS k={k} ({rollouts}r)"
                else:  # mixed
                    honest = self.get_input("Agente honesto", "mcts", ["greedy", "mcts"])
                    rollouts = self.get_input(f"Rollouts para mixed k={k}", str(self.global_config['default_rollouts']), input_type=int)
                    cmd = base_cmd + f' --mixed_agents --honest_agent {honest} --rollouts {rollouts} --note "confidence_mixed_{honest}_k{k}"'
                    desc = f"Confidence Analysis - Mixed ({honest} honest) k={k}"
                
                self.experiments.append((cmd, desc))
        
        # Restaurar configuraci√≥n original
        self.global_config['track_confidence'] = original_track
        
        total_experiments = len(agent_types) * len(k_values)
        print(f"‚úÖ A√±adidos {total_experiments} experimentos de an√°lisis de confianza")

    def _add_unrestricted_pixel_experiments(self):
        """A√±ade experimentos con selecci√≥n irrestricta de p√≠xeles."""
        print("\nüö´ EXPERIMENTOS CON P√çXELES IRRESTRICTOS")
        print("-" * 40)
        print("Permite a los agentes seleccionar CUALQUIER p√≠xel, incluyendo p√≠xeles negros,")
        print("para analizar estrategias emergentes y robustez del sistema.")
        
        # Temporalmente forzar allow_all_pixels
        original_allow = self.global_config['allow_all_pixels']
        self.global_config['allow_all_pixels'] = True
        
        experiment_types = []
        if self.get_yes_no("‚Ä¢ Comparaci√≥n: restringido vs irrestricto (mismo setup)"):
            experiment_types.append("comparison")
        if self.get_yes_no("‚Ä¢ Exploraci√≥n de estrategias adversariales"):
            experiment_types.append("adversarial")
        if self.get_yes_no("‚Ä¢ An√°lisis de robustez con p√≠xeles negros"):
            experiment_types.append("robustness")
        
        if not experiment_types:
            self.global_config['allow_all_pixels'] = original_allow
            return
        
        agent_type = self.get_input("Tipo de agente principal", "greedy", ["greedy", "mcts", "mixed"])
        n_images = self.get_input("Im√°genes por experimento", str(self.global_config['default_images_mcts']), input_type=int)
        
        if "comparison" in experiment_types:
            # Experimentos de comparaci√≥n directa
            advanced_flags = self._get_advanced_flags()
            base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                       f"--thr {self.global_config['thr']} --n_images {n_images} --seed {self.global_config['seed']}")
            
            # Con restricci√≥n (temporalmente: quitar allow_all_pixels)
            self.global_config['allow_all_pixels'] = False
            restricted_flags = self._get_advanced_flags()
            self.global_config['allow_all_pixels'] = True
            
            if agent_type == "greedy":
                # Restringido
                cmd_restricted = base_cmd + restricted_flags + ' --agent_type greedy --note "comparison_restricted_greedy"'
                self.experiments.append((cmd_restricted, "Comparison - Greedy RESTRICTED pixels"))
                # Irrestricto
                cmd_unrestricted = base_cmd + advanced_flags + ' --agent_type greedy --note "comparison_unrestricted_greedy"'
                self.experiments.append((cmd_unrestricted, "Comparison - Greedy UNRESTRICTED pixels"))
        
        if "adversarial" in experiment_types:
            # Experimentos adversariales
            advanced_flags = self._get_advanced_flags()
            for k in [4, 6, 8]:
                cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {k} "
                       f"--thr 0.0 --n_images {n_images} --agent_type {agent_type} --seed {self.global_config['seed']}{advanced_flags} "
                       f'--note "adversarial_unrestricted_{agent_type}_k{k}"')
                self.experiments.append((cmd, f"Adversarial - {agent_type.upper()} k={k} (unrestricted)"))
        
        if "robustness" in experiment_types:
            # Experimentos de robustez
            advanced_flags = self._get_advanced_flags()
            for thr in [0.0, 0.1, 0.3]:
                cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                       f"--thr {thr} --n_images {n_images} --agent_type {agent_type} --seed {self.global_config['seed']}{advanced_flags} "
                       f'--note "robustness_unrestricted_{agent_type}_thr{thr}"')
                self.experiments.append((cmd, f"Robustness - {agent_type.upper()} thr={thr} (unrestricted)"))
        
        # Restaurar configuraci√≥n original
        self.global_config['allow_all_pixels'] = original_allow
        
        print(f"‚úÖ A√±adidos experimentos de p√≠xeles irrestrictos")
        print(f"    Los agentes pueden ahora seleccionar p√≠xeles negros y explorar nuevas estrategias")

    def _add_judge_evaluation_experiments(self):
        """A√±ade experimentos espec√≠ficos de evaluaci√≥n del juez con agentes."""
        print("\nü§ñ EXPERIMENTOS DE EVALUACI√ìN DE JUEZ")
        print("-" * 40)
        print("Eval√∫a la capacidad del juez con diferentes estrategias de selecci√≥n de p√≠xeles")
        print("incluyendo agentes que seleccionan p√≠xeles secuencialmente.")
        
        experiment_types = []
        if self.get_yes_no("‚Ä¢ Comparaci√≥n de todas las estrategias (8 estrategias)"):
            experiment_types.append("full_comparison")
        if self.get_yes_no("‚Ä¢ An√°lisis de agentes vs estrategias est√°ticas"):
            experiment_types.append("agent_vs_static")
        if self.get_yes_no("‚Ä¢ An√°lisis de escalabilidad de agentes (diferentes k)"):
            experiment_types.append("agent_scalability")
        if self.get_yes_no("‚Ä¢ An√°lisis de rollouts para MCTS"):
            experiment_types.append("mcts_rollouts")
        
        if not experiment_types:
            return
        
        n_images = self.get_input("Im√°genes por experimento", "300", input_type=int)
        
        if "full_comparison" in experiment_types:
            # Comparaci√≥n completa de todas las estrategias
            strategies = ["random", "optimal", "adversarial", "adversarial_nonzero", 
                         "greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"]
            
            for strategy in strategies:
                cmd = (f"python eval_judge.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                       f"--thr {self.global_config['thr']} --strategy {strategy} --n_images {n_images} "
                       f"--seed {self.global_config['seed']}")
                
                if strategy in ["mcts_agent", "mcts_adversarial_agent"]:
                    cmd += " --rollouts 300"
                
                cmd += f' --note "judge_eval_comparison_{strategy}"'
                
                desc = f"Judge Eval - {strategy.replace('_', ' ').title()}"
                self.experiments.append((cmd, desc))
        
        if "agent_vs_static" in experiment_types:
            # Comparaci√≥n directa agentes vs est√°ticas con mismas condiciones
            for k in [4, 6, 8]:
                base_cmd = (f"python eval_judge.py --judge_name {self.global_config['judge_name']} "
                           f"--resolution {self.global_config['resolution']} --k {k} "
                           f"--thr {self.global_config['thr']} --n_images {n_images} --seed {self.global_config['seed']}")
                
                # Est√°ticas
                for strategy in ["random", "optimal"]:
                    cmd = base_cmd + f' --strategy {strategy} --note "judge_eval_static_{strategy}_k{k}"'
                    self.experiments.append((cmd, f"Judge Eval - {strategy.title()} k={k}"))
                
                # Agentes
                for agent in ["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"]:
                    cmd = base_cmd + f' --strategy {agent}'
                    if agent in ["mcts_agent", "mcts_adversarial_agent"]:
                        cmd += " --rollouts 200"
                    cmd += f' --note "judge_eval_agent_{agent}_k{k}"'
                    self.experiments.append((cmd, f"Judge Eval - {agent.replace('_', ' ').title()} k={k}"))
        
        if "agent_scalability" in experiment_types:
            # An√°lisis de escalabilidad de agentes
            for agent in ["greedy_agent", "mcts_agent", "greedy_adversarial_agent", "mcts_adversarial_agent"]:
                for k in [3, 4, 5, 6, 7, 8, 10]:
                    cmd = (f"python eval_judge.py --judge_name {self.global_config['judge_name']} "
                           f"--resolution {self.global_config['resolution']} --k {k} "
                           f"--thr {self.global_config['thr']} --strategy {agent} --n_images {n_images} "
                           f"--seed {self.global_config['seed']}")
                    
                    if agent in ["mcts_agent", "mcts_adversarial_agent"]:
                        cmd += " --rollouts 200"
                    
                    cmd += f' --note "judge_eval_scalability_{agent}_k{k}"'
                    self.experiments.append((cmd, f"Judge Eval Scalability - {agent.replace('_', ' ').title()} k={k}"))
        
        if "mcts_rollouts" in experiment_types:
            # An√°lisis de rollouts para MCTS
            for rollouts in [50, 100, 200, 500, 1000]:
                cmd = (f"python eval_judge.py --judge_name {self.global_config['judge_name']} "
                       f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                       f"--thr {self.global_config['thr']} --strategy mcts_agent --rollouts {rollouts} "
                       f"--n_images {n_images} --seed {self.global_config['seed']} --note judge_eval_mcts_r{rollouts}")
                
                self.experiments.append((cmd, f"Judge Eval - MCTS {rollouts} rollouts"))
        
        total_added = len([exp for exp in self.experiments 
                          if "judge_eval" in exp[0]])
        print(f"‚úÖ A√±adidos experimentos de evaluaci√≥n de juez")
        print(f"    Total: {total_added} experimentos que eval√∫an capacidades del juez")

    def _add_custom_experiments(self):
        """A√±ade experimentos completamente personalizados."""
        print("\nüî¨ EXPERIMENTO PERSONALIZADO")
        print("-" * 40)
        print("Configura un experimento con control total sobre todos los par√°metros")
        
        # Construir comando paso a paso
        cmd = f"python run_debate.py --judge_name {self.global_config['judge_name']}"
        cmd += f" --resolution {self.global_config['resolution']}"
        
        # k personalizado
        k = self.get_input("P√≠xeles (k)", str(self.global_config['k']), input_type=int)
        cmd += f" --k {k}"
        
        # threshold
        thr = self.get_input("Threshold", str(self.global_config['thr']), input_type=float)
        cmd += f" --thr {thr}"
        
        # Tipo de agente
        print("\nTipo de debate:")
        print("1. Greedy vs Greedy")
        print("2. MCTS vs MCTS")
        print("3. Mixed (diferentes tipos)")
        
        debate_type = self.get_input("Selecciona", "1", ["1", "2", "3"])
        
        if debate_type == "1":
            cmd += " --agent_type greedy"
            agent_desc = "Greedy"
        elif debate_type == "2":
            rollouts = self.get_input("Rollouts", "500", input_type=int)
            cmd += f" --agent_type mcts --rollouts {rollouts}"
            agent_desc = f"MCTS ({rollouts}r)"
        else:
            honest = self.get_input("Agente honesto (greedy/mcts)", "mcts", ["greedy", "mcts"])
            rollouts = self.get_input("Rollouts para MCTS", "500", input_type=int)
            cmd += f" --mixed_agents --honest_agent {honest} --rollouts {rollouts}"
            agent_desc = f"Mixed ({honest} honest)"
        
        # Otros par√°metros
        n_images = self.get_input("N√∫mero de im√°genes", "100", input_type=int)
        cmd += f" --n_images {n_images}"
        
        if self.get_yes_no("¬øUsar precommit?"):
            cmd += " --precommit"
            
        if self.get_yes_no("¬øHonest empieza primero?"):
            cmd += " --starts honest"
        
        # Opciones avanzadas
        if self.get_yes_no("¬øPermitir selecci√≥n irrestricta de p√≠xeles?"):
            cmd += " --allow_all_pixels"
        
        if self.get_yes_no("¬øTrackear confianza del juez?"):
            cmd += " --track_confidence"
        
        if self.get_yes_no("¬øGuardar datos completos en formato JSON?"):
            cmd += " --save_json"
        
        cmd += f" --seed {self.global_config['seed']}"
            
        note = self.get_input("Nota descriptiva", f"custom_{agent_desc}")
        cmd += f' --note "{note}"'
        
        # Visualizaciones
        advanced_flags = self._get_advanced_flags()
        cmd += advanced_flags
        
        desc = self.get_input("Descripci√≥n del experimento", f"Custom - {agent_desc}")
        
        self.experiments.append((cmd, desc))
        print("‚úÖ Experimento personalizado a√±adido")

    def _show_experiment_queue(self):
        """Muestra y gestiona la cola de experimentos."""
        if not self.experiments:
            print("\n‚ùå No hay experimentos en la cola")
            return
            
        print("\n" + "="*80)
        print(f"üìä COLA DE EXPERIMENTOS ({len(self.experiments)} total)")
        print("="*80)
        
        for i, (cmd, desc) in enumerate(self.experiments, 1):
            print(f"{i:3d}. {desc}")
        
        print("\nOpciones de gesti√≥n:")
        print("1. üìù Ver comando completo de un experimento")
        print("2. ‚ùå Eliminar experimento espec√≠fico")
        print("3. üóëÔ∏è Limpiar toda la cola")
        print("4. ‚è≠Ô∏è Reordenar experimentos")
        print("5. üìã Exportar lista de comandos")
        print("0. ‚Ü©Ô∏è Volver")
        
        choice = self.get_input("Selecciona", "0")
        
        if choice == "1":
            idx = self.get_input("N√∫mero de experimento a ver", input_type=int) - 1
            if 0 <= idx < len(self.experiments):
                cmd, desc = self.experiments[idx]
                print(f"\nüìã Experimento {idx+1}: {desc}")
                print(f"üîß Comando: {cmd}")
        elif choice == "2":
            idx = self.get_input("N√∫mero a eliminar", input_type=int) - 1
            if 0 <= idx < len(self.experiments):
                removed = self.experiments.pop(idx)
                print(f"‚úÖ Eliminado: {removed[1]}")
        elif choice == "3":
            if self.get_yes_no("¬øSeguro que quieres limpiar toda la cola?"):
                self.experiments = []
                print("‚úÖ Cola limpiada")
        elif choice == "4":
            self._reorder_experiments()
        elif choice == "5":
            self._export_commands()

    def _reorder_experiments(self):
        """Reordena experimentos en la cola."""
        if len(self.experiments) < 2:
            print("‚ùå Necesitas al menos 2 experimentos para reordenar")
            return
        
        print("Opciones de reordenamiento:")
        print("1. Mover experimento a nueva posici√≥n")
        print("2. Intercambiar dos experimentos")
        print("3. Ordenar por tipo (sim√©tricos primero)")
        
        choice = self.get_input("Selecciona", "1", ["1", "2", "3"])
        
        if choice == "1":
            idx1 = self.get_input("Mover experimento #", input_type=int) - 1
            idx2 = self.get_input("A posici√≥n #", input_type=int) - 1
            if 0 <= idx1 < len(self.experiments) and 0 <= idx2 < len(self.experiments):
                self.experiments.insert(idx2, self.experiments.pop(idx1))
                print("‚úÖ Experimento movido")
        elif choice == "2":
            idx1 = self.get_input("Primer experimento #", input_type=int) - 1
            idx2 = self.get_input("Segundo experimento #", input_type=int) - 1
            if 0 <= idx1 < len(self.experiments) and 0 <= idx2 < len(self.experiments):
                self.experiments[idx1], self.experiments[idx2] = self.experiments[idx2], self.experiments[idx1]
                print("‚úÖ Experimentos intercambiados")
        elif choice == "3":
            # Ordenar por tipo
            symmetric = [exp for exp in self.experiments if "vs" in exp[1] and exp[1].split("vs")[0].strip() == exp[1].split("vs")[1].strip().split("-")[0].strip()]
            asymmetric = [exp for exp in self.experiments if exp not in symmetric]
            self.experiments = symmetric + asymmetric
            print(f"‚úÖ Reordenados: {len(symmetric)} sim√©tricos, {len(asymmetric)} otros")

    def _export_commands(self):
        """Exporta la lista de comandos a un archivo."""
        if not self.experiments:
            print("‚ùå No hay experimentos para exportar")
            return
        
        filename = self.get_input("Nombre del archivo", "experiment_commands.txt")
        
        try:
            with open(filename, 'w') as f:
                f.write("# Lista de comandos de experimentos\n")
                f.write(f"# Generado: {datetime.now().isoformat()}\n")
                f.write(f"# Total de experimentos: {len(self.experiments)}\n\n")
                
                for i, (cmd, desc) in enumerate(self.experiments, 1):
                    f.write(f"# {i}. {desc}\n")
                    f.write(f"{cmd}\n\n")
            
            print(f"‚úÖ Comandos exportados a {filename}")
        except Exception as e:
            print(f"‚ùå Error exportando: {e}")

    def _execute_experiments(self):
        """Ejecuta todos los experimentos en la cola."""
        if not self.experiments:
            print("\n‚ùå No hay experimentos para ejecutar")
            return
            
        print("\n" + "="*80)
        print("üöÄ RESUMEN DE EJECUCI√ìN")
        print("="*80)
        print(f"Total de experimentos: {len(self.experiments)}")
        print(f"Configuraci√≥n global:")
        print(f"  ‚Ä¢ Juez: {self.global_config['judge_name']}")
        print(f"  ‚Ä¢ Resoluci√≥n: {self.global_config['resolution']}")
        print(f"  ‚Ä¢ K: {self.global_config['k']}")
        print(f"  ‚Ä¢ Opciones de guardado: {'Habilitadas' if self.config['viz_enabled'] else 'Solo CSV'}")
        
        # Advertir sobre experimentos costosos
        costly_experiments = []
        for cmd, desc in self.experiments:
            if "--rollouts" in cmd:
                try:
                    rollouts = int(cmd.split("--rollouts")[1].split()[0])
                    if rollouts > 1000:
                        costly_experiments.append((desc, rollouts))
                except:
                    pass
        
        if costly_experiments:
            print("\n‚ö†Ô∏è  ADVERTENCIA: Los siguientes experimentos son computacionalmente costosos:")
            for desc, rollouts in costly_experiments:
                print(f"   ‚Ä¢ {desc} ({rollouts} rollouts)")
        
        if not self.get_yes_no("\n¬øProceder con la ejecuci√≥n?"):
            return
            
        # Ejecuci√≥n
        print("\n" + "="*80)
        print("üîÑ EJECUTANDO EXPERIMENTOS")
        print("="*80)
        
        successful = 0
        failed = 0
        start_time = datetime.now()
        
        for i, (cmd, desc) in enumerate(self.experiments, 1):
            print(f"\nüìç Experimento {i}/{len(self.experiments)} ({i/len(self.experiments)*100:.0f}%)")
            
            if self.run_command(cmd, desc):
                successful += 1
            else:
                failed += 1
                if not self.get_yes_no("‚ùå Error. ¬øContinuar con los siguientes?"):
                    break
        
        # Resumen final
        end_time = datetime.now()
        duration = end_time - start_time
        print("\n" + "="*80)
        print("üèÅ EJECUCI√ìN COMPLETADA")
        print("="*80)
        print(f"‚úÖ Exitosos: {successful}")
        print(f"‚ùå Fallidos: {failed}")
        print(f"‚è±Ô∏è Tiempo total: {duration}")
        print(f"\nüìÅ Resultados guardados en:")
        print(f"   ‚Ä¢ outputs/debates.csv - Debates sim√©tricos")
        print(f"   ‚Ä¢ outputs/debates_asimetricos.csv - Debates asim√©tricos")
        print(f"   ‚Ä¢ outputs/evaluations.csv - Evaluaciones de juez")
        if self.config['viz_enabled']:
            print(f"   ‚Ä¢ outputs/visualizations/ - Im√°genes y metadata")
        print(f"\nüí° Use option 4 (Data Analysis) to export experiment data")

    def run_command(self, cmd, description):
        """Ejecuta un comando y muestra el progreso."""
        print(f"\n{'='*60}")
        print(f"üöÄ {description}")
        print(f"üìù {cmd}")
        print(f"{'='*60}")
        
        try:
            result = subprocess.run(cmd, shell=True, check=True)
            print(f"‚úÖ Completado exitosamente")
            return True
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Error: {e}")
            return False

    def show_previous_results(self):
        """Muestra resumen de resultados anteriores."""
        print("\n" + "="*80)
        print("üìä RESULTADOS ANTERIORES")
        print("="*80)
        print("Resumen de experimentos ejecutados y datos generados")
        
        # Verificar archivos CSV
        files_to_check = [
            ("outputs/debates.csv", "Debates sim√©tricos"),
            ("outputs/debates_asimetricos.csv", "Debates asim√©tricos"),
            ("outputs/evaluations.csv", "Evaluaciones de juez"),
            ("outputs/judges.csv", "Jueces entrenados")
        ]
        
        total_records = 0
        for filepath, desc in files_to_check:
            if os.path.exists(filepath):
                print(f"\nüìÑ {desc} ({filepath}):")
                try:
                    with open(filepath, 'r') as f:
                        lines = f.readlines()
                        if len(lines) > 1:
                            records = len(lines)-1
                            total_records += records
                            print(f"   üìä Total de registros: {records}")
                            print("   üìà √öltimos resultados:")
                            for line in lines[-3:]:
                                if line.strip() and not line.startswith("timestamp"):
                                    parts = line.strip().split(',')
                                    if len(parts) > 2:
                                        if "judges.csv" in filepath:
                                            if len(parts) > 10:
                                                print(f"   - {parts[1]}: acc={parts[10]}")
                                        else:
                                            if len(parts) > 2:
                                                print(f"   - {parts[1]}: acc={parts[-2]}")
                except Exception as e:
                    print(f"   ‚ùå Error leyendo archivo: {e}")
            else:
                print(f"\n‚ùå No encontrado: {filepath}")
        
        print(f"\nüìà RESUMEN TOTAL:")
        print(f"   ‚Ä¢ Total de registros en todos los archivos: {total_records}")
        
        # Check data exports
        if os.path.exists("analysis/output"):
            csv_files = [f for f in os.listdir("outputs") if f.endswith('.csv')]
            print(f"   ‚Ä¢ CSV data files available: {len(csv_files)}")
        
        print(f"\nüí° Consejos:")
        print(f"   ‚Ä¢ Use option 4 to access data analysis tools")
        print(f"   ‚Ä¢ Los archivos CSV pueden abrirse con Excel o Python/pandas")
        print(f"   ‚Ä¢ CSV files ready for custom analysis and visualization")

    def _save_configuration(self):
        """Guarda la configuraci√≥n actual."""
        print("\nüíæ GUARDAR CONFIGURACI√ìN")
        print("Guarda la configuraci√≥n completa para reutilizaci√≥n futura")
        
        filename = self.get_input("Nombre del archivo", "config_experimentos")
        if not filename.endswith('.json'):
            filename += '.json'
            
        config_data = {
            "global_config": self.global_config,
            "config": self.config,
            "experiments": self.experiments,
            "timestamp": datetime.now().isoformat(),
            "version": "3.3",
            "description": f"Configuraci√≥n con {len(self.experiments)} experimentos"
        }
        
        filepath = get_config_path(filename)
        
        try:
            with open(filepath, 'w') as f:
                json.dump(config_data, f, indent=2)
                
            print(f"‚úÖ Configuraci√≥n guardada en {filepath}")
            print(f"üìã Incluye:")
            print(f"   ‚Ä¢ Configuraci√≥n global: {self.global_config['judge_name']}, k={self.global_config['k']}")
            print(f"   ‚Ä¢ Configuraci√≥n de guardado: {'Habilitada' if self.config['viz_enabled'] else 'Solo CSV'}")
            print(f"   ‚Ä¢ Cola de experimentos: {len(self.experiments)} experimentos")
        except Exception as e:
            print(f"‚ùå Error guardando configuraci√≥n: {e}")

    def load_configuration(self):
        """Carga una configuraci√≥n guardada."""
        print("\nüìÇ CARGAR CONFIGURACI√ìN")
        print("Carga una configuraci√≥n previamente guardada")
        
        from utils.paths import CONFIGS_DIR
        if not CONFIGS_DIR.exists() or not any(CONFIGS_DIR.glob('*.json')):
            print("‚ùå No hay configuraciones guardadas")
            print("üí° Usa opci√≥n 12 en el men√∫ de experimentos para guardar configuraciones")
            return
            
        configs = [f.name for f in CONFIGS_DIR.glob('*.json')]
        if not configs:
            print("‚ùå No hay configuraciones guardadas")
            return
            
        print("üìÅ Configuraciones disponibles:")
        for i, config in enumerate(configs, 1):
            print(f"{i}. {config}")
            
        idx = self.get_input("Selecciona configuraci√≥n", "1", input_type=int) - 1
        if 0 <= idx < len(configs):
            filepath = get_config_path(configs[idx])
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                    
                if "global_config" in data:
                    self.global_config = data["global_config"]
                self.config = data["config"]
                self.experiments = data["experiments"]
                
                print(f"‚úÖ Configuraci√≥n cargada de {data.get('timestamp', 'fecha desconocida')}")
                print(f"üìã Configuraci√≥n cargada:")
                print(f"   ‚Ä¢ Juez: {self.global_config['judge_name']}")
                print(f"   ‚Ä¢ Resoluci√≥n: {self.global_config['resolution']}")
                print(f"   ‚Ä¢ K: {self.global_config['k']}")
                print(f"   ‚Ä¢ Experimentos: {len(self.experiments)}")
                print(f"   ‚Ä¢ Guardado: {'Habilitado' if self.config['viz_enabled'] else 'Solo CSV'}")
                
            except Exception as e:
                print(f"‚ùå Error cargando configuraci√≥n: {e}")

    def create_template(self):
        """Crea templates predefinidos."""
        print("\nüìù CREAR TEMPLATE DE EXPERIMENTOS")
        print("-" * 40)
        print("Templates optimizados para diferentes prop√≥sitos de investigaci√≥n")
        
        print("\nüìö Templates disponibles:")
        print("1. üìö Paper Replication - Configuraci√≥n del paper original")
        print("2. üöÄ Quick Test - Prueba r√°pida con pocos recursos")
        print("3. üî¨ Full Analysis - An√°lisis exhaustivo")
        print("4. üìä Benchmarking - Comparaci√≥n de agentes")
        print("5. üéØ Ablation Study - Estudio de ablaci√≥n completo")
        
        choice = self.get_input("Selecciona template", "1", ["1", "2", "3", "4", "5"])
        
        # Limpiar experimentos actuales
        self.experiments = []
        
        # Configurar seg√∫n template
        if choice == "1":
            self._create_paper_template()
        elif choice == "2":
            self._create_quick_template()
        elif choice == "3":
            self._create_full_template()
        elif choice == "4":
            self._create_benchmark_template()
        elif choice == "5":
            self._create_ablation_template()
            
        print(f"\n‚úÖ Template creado con {len(self.experiments)} experimentos")
        print("üìã Experimentos a√±adidos a la cola:")
        for i, (_, desc) in enumerate(self.experiments, 1):
            print(f"   {i}. {desc}")
            
        if self.get_yes_no("¬øGuardar este template?"):
            self._save_configuration()

    def _create_paper_template(self):
        """Template basado en el paper original."""
        print("\nüìö Configurando Paper Replication Template...")
        print("Replica los experimentos principales del paper AI Safety via Debate")
        
        # Configurar juez por defecto
        if "28" in self.available_judges:
            self.global_config['judge_name'] = "28"
            self.global_config['resolution'] = 28
            self.global_config['k'] = 6
        
        base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                    f"--resolution {self.global_config['resolution']} --k 6 --thr 0.0 "
                    f"--seed {self.global_config['seed']}")
        
        # Experimentos del paper
        experiments = [
            (f'{base_cmd} --agent_type greedy --n_images 1000 --note "paper_greedy_baseline"',
             "Paper - Greedy baseline"),
            (f'{base_cmd} --agent_type greedy --n_images 1000 --precommit --note "paper_greedy_precommit"',
             "Paper - Greedy precommit"),
            (f'{base_cmd} --agent_type mcts --rollouts 100 --n_images 500 --note "paper_mcts_100"',
             "Paper - MCTS 100 rollouts"),
            (f'{base_cmd} --agent_type mcts --rollouts 500 --n_images 500 --note "paper_mcts_500"',
             "Paper - MCTS 500 rollouts"),
            (f'{base_cmd} --agent_type mcts --rollouts 1000 --n_images 300 --note "paper_mcts_1000"',
             "Paper - MCTS 1000 rollouts"),
        ]
        
        self.experiments.extend(experiments)

    def _create_quick_template(self):
        """Template para pruebas r√°pidas."""
        print("\nüöÄ Configurando Quick Test Template...")
        print("Pruebas r√°pidas para verificar funcionalidad del sistema")
        
        base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                    f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                    f"--thr {self.global_config['thr']} --seed {self.global_config['seed']}")
        
        experiments = [
            (f"{base_cmd} --agent_type greedy --n_images 100 --note quick_greedy",
             "Quick - Greedy test"),
            (f"{base_cmd} --agent_type mcts --rollouts 50 --n_images 50 --note quick_mcts",
             "Quick - MCTS test"),
            (f"{base_cmd} --mixed_agents --honest_agent mcts --rollouts 50 --n_images 30 --note quick_mixed",
             "Quick - Mixed test"),
        ]
        
        self.experiments.extend(experiments)

    def _create_full_template(self):
        """Template para an√°lisis exhaustivo."""
        print("\nüî¨ Configurando Full Analysis Template...")
        print("An√°lisis exhaustivo con todas las combinaciones posibles")
        
        base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                    f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                    f"--thr {self.global_config['thr']} --seed {self.global_config['seed']}")
        
        # Combinaciones completas
        for agent in ["greedy", "mcts"]:
            for precommit in ["", " --precommit"]:
                for starts in ["liar", "honest"]:
                    n_img = 1000 if agent == "greedy" else 500
                    rollouts = " --rollouts 500" if agent == "mcts" else ""
                    
                    note = f"full_{agent}"
                    if precommit:
                        note += "_precommit"
                    note += f"_{starts}first"
                    
                    cmd = (f"{base_cmd} --agent_type {agent}{rollouts} --n_images {n_img} "
                           f"--starts {starts}{precommit} --note \"{note}\"")
                    
                    desc = f"Full - {agent.upper()}"
                    if precommit:
                        desc += " + precommit"
                    desc += f" ({starts} first)"
                    
                    self.experiments.append((cmd, desc))

    def _create_benchmark_template(self):
        """Template para benchmarking."""
        print("\nüìä Configurando Benchmarking Template...")
        print("Comparaci√≥n directa de agentes con condiciones controladas")
        
        base_cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                    f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                    f"--thr {self.global_config['thr']} --seed {self.global_config['seed']}")
        
        experiments = [
            (f"{base_cmd} --agent_type greedy --n_images 500 --note bench_greedy",
             "Benchmark - Greedy vs Greedy"),
            (f"{base_cmd} --agent_type mcts --rollouts 100 --n_images 300 --note bench_mcts_100",
             "Benchmark - MCTS 100r"),
            (f"{base_cmd} --agent_type mcts --rollouts 500 --n_images 300 --note bench_mcts_500",
             "Benchmark - MCTS 500r"),
            (f"{base_cmd} --agent_type mcts --rollouts 1000 --n_images 200 --note bench_mcts_1000",
             "Benchmark - MCTS 1000r"),
            (f"{base_cmd} --mixed_agents --honest_agent mcts --rollouts 500 --n_images 300 --note bench_mixed_mcts_h",
             "Benchmark - MCTS honest vs Greedy liar"),
            (f"{base_cmd} --mixed_agents --honest_agent greedy --rollouts 500 --n_images 300 --note bench_mixed_greedy_h",
             "Benchmark - Greedy honest vs MCTS liar"),
        ]
        
        self.experiments.extend(experiments)

    def _create_ablation_template(self):
        """Template para estudio de ablaci√≥n."""
        print("\nüéØ Configurando Ablation Study Template...")
        print("Estudio sistem√°tico de par√°metros k y rollouts")
        
        # Ablaci√≥n de k
        for k in [3, 4, 5, 6, 8, 10]:
            cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                   f"--resolution {self.global_config['resolution']} --k {k} "
                   f"--thr {self.global_config['thr']} --agent_type greedy --n_images 500 "
                   f"--seed {self.global_config['seed']} --note ablation_k{k}")
            self.experiments.append((cmd, f"Ablation - k={k}"))
        
        # Ablaci√≥n de rollouts
        for r in [50, 100, 200, 500, 1000, 2000]:
            cmd = (f"python run_debate.py --judge_name {self.global_config['judge_name']} "
                   f"--resolution {self.global_config['resolution']} --k {self.global_config['k']} "
                   f"--thr {self.global_config['thr']} --agent_type mcts --rollouts {r} "
                   f"--n_images 200 --seed {self.global_config['seed']} --note ablation_r{r}")
            self.experiments.append((cmd, f"Ablation - {r} rollouts"))

def main():
    """Punto de entrada principal."""
    manager = ExperimentManager()
    manager.print_banner()
    manager.scan_available_judges()
    manager.show_main_menu()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå Ejecuci√≥n interrumpida por el usuario")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nüí• Error inesperado: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)